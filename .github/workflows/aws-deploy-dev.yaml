name: deploy-aws-dev

on:
  push:
    branches:
      - develop
    paths:
      - .github/workflows/aws-deploy-dev.yaml
      - crawler/**
      - frontend/**
      - cdk/**
      - types/**

  # # run every 6 hours
  # only runs on the base branch, weird, github????
  # schedule:
  #   - cron: "0 */6 * * *"

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

concurrency:
  group: develop
  cancel-in-progress: false

env:
  NODE_VERSION: 22.17.0

jobs:
  aws_deploy_dev:
    runs-on: ubuntu-latest

    environment:
      name: develop
      url: https://develop.lemmyverse.net

    steps:
      # https://github.com/actions/toolkit/issues/946#issuecomment-1590016041
      - name: root suid tar
        run: sudo chown root:root /bin/tar && sudo chmod u+s /bin/tar

      - uses: actions/checkout@v4

      - name: Use Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      # download latest redis database
      - name: get current hour for cache busting
        id: cache-hour
        run: echo "hour=$(date +'%Y-%m-%d-%H')" >>$GITHUB_OUTPUT

      - name: Cache Redis Dump
        id: cache-redis
        uses: actions/cache@v4
        env:
          cache-name: cache-redis
        with:
          path: ./.redis/dump.rdb
          key: cache-redis-${{ steps.cache-hour.outputs.hour }}

      # download redis db dump from s3
      - name: Download the Redis Dump
        if: steps.cache-redis.outputs.cache-hit != 'true'
        uses: keithweaver/aws-s3-github-action@v1.0.0
        with:
          command: cp
          source: s3://${{ vars.BUILD_S3_BUCKET }}/checkpoint/dump.rdb
          destination: ./.redis/dump.rdb
          aws_access_key_id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws_secret_access_key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws_region: ap-southeast-2

      # set compose_command envvar
      - name: set global workflow ennvvar
        run: echo "COMPOSE_COMMAND=docker compose -f docker-compose.github.yaml" >> $GITHUB_ENV

      # start redis & check if it is running
      - name: Start Redis
        working-directory: ./crawler
        run: ${{ env.COMPOSE_COMMAND }}  up -d redis

      - name: Wait for Redis to be ready
        working-directory: ./crawler
        run: |
          until ${{ env.COMPOSE_COMMAND }} exec redis redis-cli ping | grep PONG; do

            ${{ env.COMPOSE_COMMAND }} logs -n 100 redis

            echo "Waiting for Redis..."
            sleep 1
          done

      - working-directory: ./crawler
        run: docker ps -a
      - working-directory: ./crawler
        run: ${{ env.COMPOSE_COMMAND }} logs redis

      # Install + Cache Crawler Dependencies
      - name: Cache Node Modules | Crawler
        id: cache-crawler-yarn
        uses: actions/cache@v4
        env:
          cache-name: cache-crawler-yarn
        with:
          path: ./crawler/node_modules/
          key: cache-crawler-yarn-${{ hashFiles('crawler/yarn.lock') }}

      - name: Install Node Modules | Crawler
        if: steps.cache-crawler-yarn.outputs.cache-hit != 'true'
        run: yarn --frozen-lockfile
        working-directory: ./crawler

      # Run Crawler Output Script
      - name: Run Health Script
        run: yarn health
        working-directory: ./crawler

      - name: Run Output Script
        run: yarn output
        working-directory: ./crawler

      # store the json files as artifacts
      - name: archive json artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-json-bundle
          path: |
            ./frontend/public/data/

      # Install + Cache Frontend Dependencies
      - name: Cache Node Modules | Frontend
        id: cache-frontend-yarn
        uses: actions/cache@v4
        env:
          cache-name: cache-frontend-yarn
        with:
          path: ./frontend/node_modules/
          key: cache-frontend-yarn-${{ hashFiles('frontend/yarn.lock') }}

      - name: Install Node Modules | Frontend
        if: steps.cache-frontend-yarn.outputs.cache-hit != 'true'
        run: yarn --frozen-lockfile
        working-directory: ./frontend

      # Build Frontend to ./frontend/dist
      - name: Build the Frontend
        run: yarn build
        working-directory: ./frontend

      - name: Create CDK Config JSON
        id: create-json
        uses: jsdaniell/create-json@v1.2.3
        with:
          dir: ./cdk
          name: "config.json"
          json: ${{ vars.CONFIG_JSON }}

      # Install + Cache CDK Dependencies
      - name: Cache Node Modules | CDK
        id: cache-cdk-yarn
        uses: actions/cache@v4
        env:
          cache-name: cache-cdk-yarn
        with:
          path: ./cdk/node_modules/
          key: cache-cdk-yarn-${{ hashFiles('cdk/yarn.lock') }}

      - name: Install Node Modules | CDK
        if: steps.cache-cdk-yarn.outputs.cache-hit != 'true'
        run: yarn --frozen-lockfile
        working-directory: ./cdk

      - name: CDK Bootstrap
        run: yarn bootstrap
        working-directory: ./cdk
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: CDK Synth
        run: yarn synth
        working-directory: ./cdk
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: CDK Diff
        run: yarn diff
        working-directory: ./cdk
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      - name: CDK Deploy
        run: yarn deploy:ci
        working-directory: ./cdk
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      # stop redis
      - name: Stop Redis
        working-directory: ./crawler
        if: always()
        run: ${{ env.COMPOSE_COMMAND }} down
