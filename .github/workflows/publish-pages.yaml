name: publish-pages

on:
  # Runs on pushes targeting the default branch
  push:
    branches:
      - main
    paths:
      - .github/workflows/publish-pages.yaml
      - pages/**
      - frontend/**
      - crawler/**
      - types/**

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

  # run every 6 hours
  schedule:
    - cron: "0 */6 * * *"

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: pages
  cancel-in-progress: false

env:
  NODE_VERSION: 22.17.0

jobs:
  # download the redis dump from s3
  # create the json files for the redis data
  # upload the json files to github artifacts
  publish_pages:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}

    steps:
      # https://github.com/actions/toolkit/issues/946#issuecomment-1590016041
      - name: root suid tar
        run: sudo chown root:root /bin/tar && sudo chmod u+s /bin/tar

      - uses: actions/checkout@v4

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Use Node.js ${{ env.NODE_VERSION }}
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      # Download + Start Redis Docker
      - name: Get Dump + Start Redis
        uses: ./.github/actions/start-redis
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          s3-bucket: ${{ vars.BUILD_S3_BUCKET }}

      # Yarn Install ./crawler
      - name: Yarn Install ./crawler
        uses: ./.github/actions/yarn-install
        with:
          working-directory: ./crawler

      # Run Crawler Output Script
      - name: Run Health Script
        run: yarn health
        working-directory: ./crawler

      - name: Run Output Script
        run: yarn output
        working-directory: ./crawler

      # Create ZIP Archive of JSON Files in ./frontend/public/data/
      - name: Create ZIP Archive of JSON Files
        working-directory: ./frontend/public/data
        run: |
          zip -r -9 -q json-bundle.zip ./*
          du -sh json-bundle.zip

      - name: copy the json files to github pages
        working-directory: ./
        run: cp -r ./frontend/public/data/ ./pages/public/

      - name: copy the raw db dump file to github pages
        working-directory: ./
        run: cp -r ./.redis/dump.rdb ./pages/public/data/lemmyverse.rdb

      # Yarn Install ./pages
      - name: Yarn Install ./pages
        uses: ./.github/actions/yarn-install
        with:
          working-directory: ./pages

      - name: Build the Frontend for Pages
        run: yarn build
        working-directory: ./pages

      # upload pages
      - name: upload github pages artifacts
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./pages/dist/

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
